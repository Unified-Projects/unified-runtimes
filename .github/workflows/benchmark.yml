name: Benchmark

on:
    push:
        branches: ["main", "dev"]
    workflow_dispatch:
        inputs:
            duration:
                description: "Benchmark duration in seconds"
                required: false
                default: "30"
            runtime_image:
                description: "Runtime image to test with"
                required: false
                default: "openruntimes/node:v5-22"
            function:
                description: "Function type (node, nextjs)"
                required: false
                default: "node"

env:
    CARGO_TERM_COLOR: always
    BENCH_SECRET: benchmark-secret
    BENCH_DURATION: ${{ github.event.inputs.duration || '30' }}
    BENCH_RUNTIME_IMAGE: ${{ github.event.inputs.runtime_image || 'openruntimes/node:v5-22' }}
    BENCH_FUNCTION: ${{ github.event.inputs.function || 'node' }}
    BENCH_OUTPUT_JSON: benchmark_results.json

jobs:
    benchmark:
        name: Performance Benchmark
        runs-on: ubuntu-latest
        permissions:
            contents: read
        steps:
            - name: Checkout repository
              uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # v3

            - name: Pre-clean Stale Containers
              run: |
                  # Remove any stale containers and networks from previous runs
                  docker compose -f crates/urt-executor/docker-compose.test.yml \
                    --profile test --profile bench down -v --remove-orphans 2>/dev/null || true
                  docker ps -a --filter "label=urt.managed" -q | xargs -r docker rm -f 2>/dev/null || true
                  docker network rm e2e-test-network 2>/dev/null || true

            - name: Run Dockerized Benchmarks
              run: |
                  docker compose -f crates/urt-executor/docker-compose.test.yml \
                    --profile bench up --build --abort-on-container-exit --exit-code-from bench-runner

            - name: Capture Benchmark Output
              if: always()
              run: |
                  docker compose -f crates/urt-executor/docker-compose.test.yml \
                    logs --no-color bench-runner > benchmark_output.txt || true

                  BENCH_CONTAINER_ID=$(docker compose -f crates/urt-executor/docker-compose.test.yml ps -q bench-runner)
                  if [ -n "$BENCH_CONTAINER_ID" ]; then
                      docker cp "$BENCH_CONTAINER_ID:/app/${BENCH_OUTPUT_JSON}" "${BENCH_OUTPUT_JSON}" || true
                  fi
            - name: Write Benchmark Summary
              if: always()
              run: |
                  {
                      echo "## Benchmark Summary"
                      echo ""
                      if [ -f benchmark_results.json ]; then
                          echo "| Benchmark | RPS | Success % | p50 (ms) | p90 (ms) | p99 (ms) |"
                          echo "|-----------|-----|-----------|----------|----------|----------|"
                          jq -r '
                              def success: if .total_requests == 0 then 0 else (.successful_requests / .total_requests * 100) end;
                              def row($name):
                                  if . == null then empty
                                  else "| \($name) | \(.rps|sprintf(\"%.2f\")) | \(success|sprintf(\"%.2f\"))% | \(.latency.p50_ms|sprintf(\"%.2f\")) | \(.latency.p90_ms|sprintf(\"%.2f\")) | \(.latency.p99_ms|sprintf(\"%.2f\")) |"
                                  end;
                              (.urt // {}) as $u |
                              [
                                  $u.ping | row("Ping Endpoint"),
                                  $u.health | row("Health Endpoint"),
                                  $u.execution | row("Function Execution"),
                                  $u.list_runtimes | row("List Runtimes")
                              ] | .[]' benchmark_results.json
                          echo ""
                      else
                          echo "_No benchmark_results.json found._"
                          echo ""
                      fi

                      if [ -f benchmark_output.txt ]; then
                          awk '
                              /^## URT Concurrency Scaling/ {printing=1}
                              printing {print}
                              /^\\| Concurrency \\|/ {table=1}
                              table && /^$/ {exit}
                          ' benchmark_output.txt
                          echo ""
                      fi
                  } >> "$GITHUB_STEP_SUMMARY"

            - name: Upload Results
              if: always()
              uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
              with:
                  name: benchmark-results
                  path: |
                      benchmark_output.txt
                      benchmark_results.json
                  retention-days: 90

            - name: Show Executor Logs on Failure
              if: failure()
              run: |
                  echo "=== URT Executor Logs ==="
                  docker compose -f crates/urt-executor/docker-compose.test.yml \
                    logs --no-color urt-executor | tail -100

            - name: Clean Up Resources
              if: always()
              run: |
                  docker compose -f crates/urt-executor/docker-compose.test.yml down -v --remove-orphans 2>/dev/null || true
                  docker ps -a --filter "label=urt.managed" -q | xargs -r docker rm -f 2>/dev/null || true
                  docker network rm e2e-test-network 2>/dev/null || true
                  docker system prune -f 2>/dev/null || true
                  docker volume prune -f 2>/dev/null || true
                  rm -f benchmark_output.txt benchmark_results.json 2>/dev/null || true
